{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Model In Pytorch\n",
    "\n",
    "This tutorial is adapted from [this](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). \n",
    "\n",
    "We will learn the common procedure of training DL models via the image classification, a typical supervised machine learning task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"       # eg. \"0, 1, 2\" for multiple\n",
    "\n",
    "DATA_ROOT = '/data1/cifar/'\n",
    "DEVICE = 'cuda:0'\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spells...\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import tensorboardX\n",
    "\n",
    "writer = tensorboardX.SummaryWriter()\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchvision\n",
    "\n",
    "The library `torchvision` is a sub-project of Pytorch, with which we can load some pretrained models and several common datasets, and use some utilities for computer vision(CV).\n",
    "\n",
    "### Loading data\n",
    "\n",
    "Target dataset: [CIFAR 10](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=DATA_ROOT, train=True)\n",
    "print(trainset)\n",
    "print()\n",
    "print(trainset.train_data.shape, type(trainset.train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "\n",
    "\n",
    "We can estimate the means and standard deviations of each channel on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = trainset.train_data.mean(axis=(0, 1, 2)) / 255\n",
    "std = trainset.train_data.std(axis=(0, 1, 2), ddof=1) / 255                # What's the ddof? \n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                                     # .div_(255)\n",
    "#    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading train data and loading test data with the transformer into batch loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root=DATA_ROOT, train=True, \n",
    "                                        transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=DATA_ROOT, train=False,\n",
    "                                       transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, \n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing images in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tag, img):\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    # unnormalize\n",
    "    # npimg = npimg / 2 + 0.5\n",
    "    # Your code:\n",
    "    npimg = \n",
    "    \n",
    "    writer.add_image(tag, npimg)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow('train/'+' '.join(classes[i] for i in labels), torchvision.utils.make_grid(images, nrow=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network(CNN) Model\n",
    "\n",
    "In Pytorch, a model definition is a Python class inheritated from `torch.nn.Module`.\n",
    "\n",
    "By instantiating a Python object from the class, we can obtain a model to train.\n",
    "\n",
    "For more details about CNN, see the tutorials in [cs231n](http://cs231n.github.io/convolutional-networks/) and [theano](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_output_size(in_size, kernel_size, stride=1, padding=0, dilation=1):\n",
    "    return math.floor((in_size + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5, padding=2),              # Check the meanings of each argument.\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(, ),                  # Fill it!\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.cnn2(x)\n",
    "        \n",
    "        # Your code:\n",
    "        x = \n",
    "        \n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)       # Instantiate a model and put all the parameters of it into the device\n",
    "\n",
    "writer.add_graph(net, torch.zeros(1, 3, 32, 32, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "In this tutorial, we just use Cross-Entropy Loss, a loss function commonly for classification.\n",
    "\n",
    "For more details about loss function will be introduced in the futrue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "Also, we employ a basic optimizer called Stochastic Gradient Descent(SGD) with momentum and defer the explanation.\n",
    "\n",
    "The first argument passed to the optimizer is a iterable object of all the parameters you want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):                           # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # set the model in training mode\n",
    "        net.train()\n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # Your code:\n",
    "        inputs, labels = \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    writer.add_scalar('loss', total_loss/(i+1), epoch+1)\n",
    "        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow('test/'+'_'.join(classes[i] for i in labels), torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[i] for i in labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train(False)                         # set the model in testing mode.\n",
    "outputs = net(images.to(device))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[i] for i in predicted))\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# set the model in validation mode\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)      # the second return value is indices of the maximums\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += int((predicted == labels).sum())   # sum boolean mask into total correct results; 0d-tensor to int\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Performances on each classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = [0.] * 10\n",
    "class_total = [0.] * 10\n",
    "\n",
    "# Your codes:\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "DLLecture",
   "language": "python",
   "name": "dllecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
