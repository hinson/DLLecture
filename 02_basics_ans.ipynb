{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Constructing Deep Learning Models with TensorFlow/Pytorch\n",
    "\n",
    "##  Tensorflow and Pytorch\n",
    "\n",
    "* Many deep learning libraries have been developed util now: TensorFlow, Pytorch, Caffe, Mxnet, CNTK...\n",
    "* According to the resent reports, TensorFlow and Pytorch are the most popular libraries in deep learning research.\n",
    "* TensorFlow is suited to constructing static graph models, while Pytorch is good at dynamic(eager) modeling.\n",
    "* Though TensorFlow 2.0 will make earger mode be default, and Pytorch 1.0 will include caffe to handle static models,  at this time, we still employ them in the most suitable way separately.\n",
    "\n",
    "\n",
    "## Tensors\n",
    "\n",
    "Matrices are not enough in deep learning, since\n",
    "\n",
    "* one instance may be a 2d-array or over.\n",
    "    * a sentance: $ \\#\\left|\\{\\text{dims of word embedding}\\}\\right| \\times \\#\\left|\\{\\text{words of the sentance}\\}\\right| $\n",
    "    * a color image: $ \\#\\left|\\text{(R, G, B)}\\right| \\times \\#\\left|\\{\\text{horizontal pixels}\\}\\right| \\times \\#\\left|\\{\\text{vertical pixels}\\}\\right| $\n",
    "* mini-batch training is used commonly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment variables about use of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"       # eg. \"0, 1, 2\" for multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Numpy\n",
    "\n",
    "#### Creation\n",
    "* `np.array` is the most common API to create an N dimensions(nd-) array. \n",
    "\n",
    "* About other creation APIs see [creation routines](https://docs.scipy.org/doc/numpy/reference/routines.array-creation.html) and [random sampling](https://docs.scipy.org/doc/numpy/reference/routines.random.html).\n",
    "\n",
    "* Operations on nd-arrays \"broadcast\" while the operands have different shapes. See [this](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr =\n",
      " [0. 1. 2. 3.] \n",
      " shape = (4,) \n",
      " ndim = 1 \n",
      " dtype = float32 \n",
      " type = <class 'numpy.ndarray'> \n",
      "\n",
      "vec =\n",
      " [[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]] \n",
      " shape = (4, 1) \n",
      " ndim = 2 \n",
      " dtype = float32 \n",
      " type = <class 'numpy.ndarray'> \n",
      "\n",
      "mat =\n",
      " [[0.  1.  4.  9. ]\n",
      " [1.  0.  2.  0.5]\n",
      " [2.  1.  4.  1. ]\n",
      " [3.  2.  6.  1.5]\n",
      " [4.  3.  8.  2. ]] \n",
      " shape = (5, 4) \n",
      " ndim = 2 \n",
      " dtype = float32 \n",
      " type = <class 'numpy.ndarray'> \n",
      "\n",
      "ten =\n",
      " [[[0.  1.  4.  9. ]\n",
      "  [1.  0.  2.  0.5]\n",
      "  [2.  1.  4.  1. ]\n",
      "  [3.  2.  6.  1.5]\n",
      "  [4.  3.  8.  2. ]]\n",
      "\n",
      " [[0.  1.  4.  9. ]\n",
      "  [1.  0.  2.  0.5]\n",
      "  [2.  1.  4.  1. ]\n",
      "  [3.  2.  6.  1.5]\n",
      "  [4.  3.  8.  2. ]]] \n",
      " shape = (2, 5, 4) \n",
      " ndim = 3 \n",
      " dtype = float32 \n",
      " type = <class 'numpy.ndarray'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_info(obj, name):\n",
    "    \n",
    "    print(\"{} =\\n\".format(name), obj, \"\\n shape =\", obj.shape, \n",
    "          \"\\n ndim =\", obj.ndim if hasattr(obj, 'ndim') else obj.ndimension(), \n",
    "          \"\\n dtype =\", obj.dtype, \"\\n type =\", type(obj), \"\\n\")\n",
    "\n",
    "arr = np.array([0., 1., 2., 3.], dtype=np.float32)\n",
    "print_info(arr, \"arr\")\n",
    "\n",
    "vec = np.array(arr+1., ndmin=2).T    # .T means transpose\n",
    "print_info(vec, \"vec\")\n",
    "\n",
    "mat = np.vstack((arr**2, np.hstack((vec, vec-1., vec*2, vec/2))))\n",
    "print_info(mat, \"mat\")\n",
    "\n",
    "ten = np.stack((mat, mat))\n",
    "print_info(ten, \"ten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing, slicing and masking\n",
    "\n",
    "* Like lists in Python core, `[]` is used to index elements in nd-arrays. \n",
    "\n",
    "* The operators in `[]` can be array-like or slices, but using array-like returns a copy of data while using slices returns a view.\n",
    "\n",
    "* However, unlike the usage of multiple `[]` to index nd-lists, eg. `ls[d0][d1]`, `,` is used in `[]` for nd-arrays, eg. `arr[d0, d1]`.\n",
    "\n",
    "* Boolean operations can be performed masking thanks to broadcasting.\n",
    "\n",
    "For more detail, see [this](https://docs.scipy.org/doc/numpy/user/basics.indexing.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 \n",
      "\n",
      "[[0.5 2. ]\n",
      " [1.  4. ]\n",
      " [1.5 6. ]\n",
      " [2.  8. ]] \n",
      "\n",
      "[0.5 4.  2.  4. ] \n",
      "\n",
      "[[4. 2. 4. 6. 8.]\n",
      " [4. 2. 4. 6. 8.]] \n",
      "\n",
      "[4.  9.  2.  2.  4.  3.  2.  6.  1.5 4.  3.  8.  2.  4.  9.  2.  2.  4.\n",
      " 3.  2.  6.  1.5 4.  3.  8.  2. ] \n",
      "\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "print(mat[3, 1], \"\\n\")\n",
    "\n",
    "print(mat[1:, -1:-3:-1], \"\\n\")     # same as [slice(1, None), slice(-1, -3, -1)]\n",
    "\n",
    "print(mat[np.arange(1, mat.shape[0]), np.array([3, 2, 1, 0])], \"\\n\")\n",
    "\n",
    "print(ten[..., 2], \"\\n\")           # same as [Ellipsis, 2]\n",
    "\n",
    "print(ten[ten>1], \"\\n\")\n",
    "\n",
    "print(arr[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With TensorFlow\n",
    "\n",
    "#### Creation\n",
    "Use the low level APIs to create a tensor object.\n",
    "\n",
    "* `tf.Variable`\n",
    "* `tf.constant`\n",
    "* `tf.placeholder`\n",
    "* `tf.SparseTensor`\n",
    "\n",
    "To know the usages of the APIs:\n",
    "1. push `shift` + `tab` while the cursor is behind the `(` of each name string to see the documentation of the API. \n",
    "2. Try to push `shift` + `tab` 2~4 times quickly.\n",
    "3. Push `esc` 1~2 times to close the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable()\n",
    "tf.random_uniform()\n",
    "tf.zeros()\n",
    "tf.placeholder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detail, see this [guide](https://www.tensorflow.org/guide/tensors).\n",
    "\n",
    "**Notice**: There is a _bug_ in the above official guide. When initializing a variable tensor with a certain dtype, do not use `tf.Variable({value}, tf.{dtype})` but `tf.Variable({value}, dtype=tf.{dtype})`. Because `dtype` is not the second argument of `tf.Variable` at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**. Create the following graph object in TensorFlow:\n",
    "* a _variable_ $ 30 \\times 48 $ random matrix $w$ with name `weight`\n",
    "* a _variable_ $48$-d zero vector $b$ with name `bias`\n",
    "* a $ 4 \\times 5 \\times 6 $ tensor _placeholder_ $x$ with name `input` \n",
    "\n",
    "All the `dtype`s must be `tf.float32`.\n",
    "\n",
    "Hints: \n",
    "1. There are many APIs to initialize variable tensor values, such as `tf.ones`, `tf.zeros`, `tf.fill` and `tf.random_*`. \n",
    "2. You can also use `numpy` to initialize variable or constant values.\n",
    "3. The names indicate the ones in TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):                        # using CPU\n",
    "    # your codes:\n",
    "    w = tf.random_uniform((30, 48), 0, 1, dtype=tf.float32, name='weight')\n",
    "    b = tf.Variable(np.zeros(48), dtype=tf.float32, name='bias')           # same as tf.zeros\n",
    "    x = tf.placeholder(tf.float32, shape=(4, 5, 6), name='input')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**. Construct a graph of $y = x'w + b$, where $x'$ is a $4 \\times 30$ matrix placeholder reshaped from $x$.\n",
    "\n",
    "Hints:\n",
    "1. Use `x_` to indicate $x'$\n",
    "2. Use `tf.matmul` or `@` to perform the matrix multiplication.\n",
    "3. Tensors broadcast operations the same as arrays in numpy. \n",
    "4. The $y$ is a $4 \\times 48$ matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):                        # using GPU\n",
    "    # your codes:\n",
    "    x_ = tf.reshape(x, (-1, 30), name='input_reshaped')             # sames (4, 30)\n",
    "    y = tf.matmul(x_, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph execution\n",
    "\n",
    "Apply `tf.Session` to create a TensorFlow session to execute operations in a graph.\n",
    "\n",
    "A session should be closed when the execution finished. We can use `with` syntax in Python to handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result =\n",
      " [[ 8.358244   8.309652   7.779122   8.227763   7.0537233  7.1728964\n",
      "   9.389893   8.024819   7.1485944  6.424975  10.394542   8.543082\n",
      "   8.750342   7.904936   8.124608   8.31452    7.604998   8.994152\n",
      "   6.3616753  9.653735   9.461673   7.726028   9.160962   8.698362\n",
      "   9.423408   8.009501  10.327158   8.63269    7.6286883  8.833927\n",
      "   7.2258496  9.192509   7.854035   8.343961   8.373005   9.335024\n",
      "   7.9447107  9.919081   9.639628   9.591763   8.400371   7.546234\n",
      "   8.400998   8.997999   6.342138   7.4642334  7.2081466  8.408829 ]\n",
      " [ 7.405282   9.07373    6.6454363  7.0295205  6.335593   7.3966513\n",
      "   7.907217   6.678685   6.2604074  5.5376782  8.235144   7.117328\n",
      "   6.977808   6.784752   8.556215   8.376909   5.840652   7.871629\n",
      "   6.1440296  8.175112   7.8326406  7.369941   8.195439   8.494647\n",
      "   7.430075   6.760482   9.397528   8.229395   6.331881   7.308034\n",
      "   6.668237   7.621803   7.1842155  8.000627   6.117611   7.5221763\n",
      "   7.376913   8.091796   8.390335   7.7559032  7.23128    6.817966\n",
      "   6.8448124  7.494427   5.716333   8.204545   6.463639   6.917542 ]\n",
      " [ 5.6953263  6.358039   5.5886245  6.2442255  5.560326   5.3513904\n",
      "   6.5299425  5.36203    5.6784897  4.029199   7.481951   6.195044\n",
      "   6.317261   6.3500247  6.039775   5.7239428  5.690527   6.498136\n",
      "   4.5663795  7.1842384  7.881795   5.5510397  6.6215167  6.4196815\n",
      "   6.3254523  6.4832196  7.4320936  5.8403287  5.636481   6.6503053\n",
      "   6.2097034  5.9424453  5.653349   6.6168103  6.1407933  6.4746814\n",
      "   6.0688186  7.3163366  7.058493   7.5204287  5.9160514  5.7168903\n",
      "   5.8084655  6.1131825  4.959134   5.704547   4.9292746  7.1704264]\n",
      " [ 6.2388935  8.245978   7.1751833  7.4295807  7.5306377  7.7717166\n",
      "   8.139567   6.6999636  8.117512   6.3705735  9.298905   7.244755\n",
      "   8.583583   7.9279256  7.663319   7.8047447  6.4311385  8.486377\n",
      "   5.1870413  8.073946   8.95004    7.6492233  8.114479   8.420926\n",
      "   8.331621   7.5289083  8.770897   8.070091   6.8876424  8.201853\n",
      "   8.07471    7.418034   7.014304   7.95844    6.810823   7.60523\n",
      "   6.4666786  9.418253   9.221164   9.007622   6.6965976  6.577087\n",
      "   7.85439    6.997391   7.0588393  7.048502   7.015594   8.06868  ]] \n",
      " shape = (4, 48) \n",
      " ndim = 2 \n",
      " dtype = float32 \n",
      " type = <class 'numpy.ndarray'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True                     # don't set false at a shared GPU environment\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    input = np.random.rand(4, 5, 6)\n",
    "    result = sess.run(y, feed_dict={x: input})\n",
    "    print_info(result, \"result\")\n",
    "    tf.summary.FileWriter('./runs', sess.graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Pytorch\n",
    "\n",
    "* Pytorch has a bundle of numpy-like APIs\n",
    "    * pythonic\n",
    "    * OOP- or functional style can be chosen in the programming.\n",
    "\n",
    "* `torch.tensor` is mainly used to create a tensor. \n",
    "* Also, there are many convenient APIs to construct some certain tensors, such as `torch.zeros`, `torch.ones` and `torch.rand*`.\n",
    "\n",
    "Now, review the process of looking up the documentations of APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor()\n",
    "torch.zeros()\n",
    "torch.rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**. Create the following tensor objects in Pytorch.\n",
    "* a $ 30 \\times 48 $ random matrix $w$\n",
    "* a $48$-d zero vector $b$\n",
    "* a $ 4 \\times 5 \\times 6 $ random tensor $x$ \n",
    "\n",
    "All the `dtype`s must be `torch.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes:\n",
    "w = torch.rand((30, 48), dtype=torch.float32)\n",
    "b = torch.zeros(48, dtype=torch.float32)\n",
    "x = torch.rand((4, 5, 6), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**. Calculate $y = x'w + b$, where $x'$ is a $4 \\times 30$ matrix reshaped from $x$.\n",
    "\n",
    "Hints:\n",
    "1. Use `{tensor}.view` rather than `torch.reshape` to flatten.\n",
    "2. Use `torch.matmul` or `@` to perform the matrix multiplication.\n",
    "3. Broadcasting works as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes:\n",
    "y = torch.matmul(x.view(-1, 30), w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y =\n",
      " tensor([[5.5667, 8.0265, 6.5486, 8.1449, 7.3204, 7.5531, 7.8389, 5.9027, 8.4445,\n",
      "         7.1179, 7.3936, 7.7458, 7.1569, 9.1940, 8.8887, 7.7558, 7.4410, 8.7810,\n",
      "         6.4504, 7.1810, 8.4517, 7.4026, 7.9868, 7.2360, 7.0586, 6.9077, 8.6155,\n",
      "         7.2232, 6.8022, 5.6862, 6.2417, 7.9757, 7.4014, 8.2183, 6.4553, 8.3895,\n",
      "         8.2536, 7.2091, 8.2178, 7.7101, 6.5175, 6.6017, 8.4134, 5.6454, 7.9216,\n",
      "         7.5809, 6.9308, 7.9102],\n",
      "        [4.7944, 7.6596, 5.3806, 7.3439, 6.3041, 7.7558, 7.2205, 6.5450, 6.8329,\n",
      "         6.0705, 7.0618, 6.7989, 7.6537, 7.7555, 8.1527, 7.7323, 6.4669, 8.0622,\n",
      "         6.6007, 8.1995, 7.4816, 6.5633, 7.8278, 7.4247, 5.1542, 6.0255, 7.4717,\n",
      "         6.0527, 6.4665, 4.9215, 5.2722, 7.2250, 6.6226, 7.0848, 6.1495, 6.4953,\n",
      "         7.9893, 6.5039, 6.4224, 8.0600, 6.8567, 5.8803, 7.0927, 5.9097, 6.2198,\n",
      "         7.8803, 6.1650, 8.1800],\n",
      "        [5.2311, 7.6031, 6.3994, 8.3263, 6.7625, 7.9609, 7.8390, 5.6355, 8.1225,\n",
      "         6.4564, 7.5129, 8.0405, 7.5251, 8.5771, 8.8767, 8.3272, 7.2706, 8.4399,\n",
      "         7.0091, 7.3125, 8.1156, 6.8476, 8.1402, 7.7542, 6.5324, 6.9541, 8.5372,\n",
      "         7.3628, 7.0600, 5.9753, 6.2624, 6.4969, 7.1089, 6.4781, 7.2452, 7.4384,\n",
      "         8.2913, 6.8070, 7.1790, 7.5475, 7.3793, 6.5735, 7.9081, 6.0437, 7.3960,\n",
      "         6.9468, 7.8197, 8.3178],\n",
      "        [5.6641, 7.3779, 6.1246, 8.8250, 6.4050, 7.5264, 7.4052, 6.7377, 7.5586,\n",
      "         7.1615, 6.5025, 7.7563, 8.6025, 9.2279, 7.6819, 7.5856, 8.1160, 7.5097,\n",
      "         5.5265, 8.4738, 8.6340, 7.3602, 8.4856, 7.7644, 5.7592, 6.8028, 7.3478,\n",
      "         6.9799, 6.5770, 5.5586, 4.6794, 7.9488, 7.4940, 8.3828, 6.5012, 8.2683,\n",
      "         7.9812, 7.5232, 7.5973, 7.4009, 6.7781, 6.4174, 7.4787, 6.5398, 6.8191,\n",
      "         8.4176, 7.0252, 7.7744]]) \n",
      " shape = torch.Size([4, 48]) \n",
      " ndim = 2 \n",
      " dtype = torch.float32 \n",
      " type = <class 'torch.Tensor'> \n",
      "\n",
      "z =\n",
      " tensor([[5.5667, 8.0265, 6.5486, 8.1449, 7.3204, 7.5531, 7.8389, 5.9027, 8.4445,\n",
      "         7.1179, 7.3936, 7.7458, 7.1569, 9.1940, 8.8887, 7.7558, 7.4410, 8.7810,\n",
      "         6.4504, 7.1810, 8.4517, 7.4026, 7.9868, 7.2360, 7.0586, 6.9077, 8.6155,\n",
      "         7.2232, 6.8022, 5.6862, 6.2417, 7.9757, 7.4014, 8.2183, 6.4553, 8.3895,\n",
      "         8.2536, 7.2091, 8.2178, 7.7101, 6.5175, 6.6017, 8.4134, 5.6454, 7.9216,\n",
      "         7.5809, 6.9308, 7.9102],\n",
      "        [4.7944, 7.6596, 5.3806, 7.3439, 6.3041, 7.7558, 7.2205, 6.5450, 6.8329,\n",
      "         6.0705, 7.0618, 6.7989, 7.6537, 7.7555, 8.1527, 7.7323, 6.4669, 8.0622,\n",
      "         6.6007, 8.1995, 7.4816, 6.5633, 7.8278, 7.4247, 5.1542, 6.0255, 7.4717,\n",
      "         6.0527, 6.4665, 4.9215, 5.2722, 7.2250, 6.6226, 7.0848, 6.1495, 6.4953,\n",
      "         7.9893, 6.5039, 6.4224, 8.0600, 6.8567, 5.8803, 7.0927, 5.9097, 6.2198,\n",
      "         7.8803, 6.1650, 8.1800],\n",
      "        [5.2311, 7.6031, 6.3994, 8.3263, 6.7625, 7.9609, 7.8390, 5.6355, 8.1225,\n",
      "         6.4564, 7.5129, 8.0405, 7.5251, 8.5771, 8.8767, 8.3272, 7.2706, 8.4399,\n",
      "         7.0091, 7.3125, 8.1156, 6.8476, 8.1402, 7.7542, 6.5324, 6.9541, 8.5372,\n",
      "         7.3628, 7.0600, 5.9753, 6.2624, 6.4969, 7.1089, 6.4781, 7.2452, 7.4384,\n",
      "         8.2913, 6.8070, 7.1790, 7.5475, 7.3793, 6.5735, 7.9081, 6.0437, 7.3960,\n",
      "         6.9468, 7.8197, 8.3178],\n",
      "        [5.6641, 7.3779, 6.1246, 8.8250, 6.4050, 7.5264, 7.4052, 6.7377, 7.5586,\n",
      "         7.1615, 6.5025, 7.7563, 8.6025, 9.2279, 7.6819, 7.5856, 8.1160, 7.5097,\n",
      "         5.5265, 8.4738, 8.6340, 7.3602, 8.4856, 7.7644, 5.7592, 6.8028, 7.3478,\n",
      "         6.9799, 6.5770, 5.5586, 4.6794, 7.9488, 7.4940, 8.3828, 6.5012, 8.2683,\n",
      "         7.9812, 7.5232, 7.5973, 7.4009, 6.7781, 6.4174, 7.4787, 6.5398, 6.8191,\n",
      "         8.4176, 7.0252, 7.7744]], device='cuda:0') \n",
      " shape = torch.Size([4, 48]) \n",
      " ndim = 2 \n",
      " dtype = torch.float32 \n",
      " type = <class 'torch.Tensor'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_info(y, 'y')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    z = y.to(device)\n",
    "    print_info(z, 'z')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors in Pytorch can be easily converted to numpy array, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_np =\n",
      " [[5.566656  8.02651   6.548632  8.144884  7.320438  7.5531383 7.8388743\n",
      "  5.9026737 8.444513  7.1178865 7.393579  7.745831  7.156865  9.194041\n",
      "  8.888714  7.755849  7.4410286 8.781012  6.4504075 7.1809797 8.45172\n",
      "  7.402625  7.9868283 7.235982  7.058561  6.907666  8.615546  7.2231636\n",
      "  6.8022313 5.6861963 6.2417436 7.9756975 7.4014196 8.218342  6.4552665\n",
      "  8.389525  8.253632  7.2090964 8.217768  7.710062  6.5174675 6.6016555\n",
      "  8.413447  5.645404  7.9215565 7.580886  6.9308214 7.9102364]\n",
      " [4.7944493 7.6595645 5.380621  7.3438683 6.304113  7.755822  7.220464\n",
      "  6.5449853 6.8328843 6.070502  7.0617924 6.7989345 7.6537113 7.7555285\n",
      "  8.152721  7.7322893 6.4669175 8.062236  6.6007056 8.1995325 7.4815793\n",
      "  6.5632544 7.8278246 7.424659  5.15418   6.0254593 7.4716516 6.0527406\n",
      "  6.4664617 4.9215183 5.272157  7.2250047 6.622629  7.084839  6.1494765\n",
      "  6.495301  7.9892516 6.503865  6.4223833 8.059981  6.8567424 5.8802686\n",
      "  7.0926504 5.909717  6.2197986 7.880308  6.1649575 8.180039 ]\n",
      " [5.2311354 7.6030865 6.3993807 8.326275  6.7624664 7.9608574 7.839047\n",
      "  5.635451  8.122471  6.4563546 7.512948  8.040508  7.525143  8.577088\n",
      "  8.876677  8.327232  7.27056   8.439892  7.0091496 7.3124533 8.11555\n",
      "  6.8475633 8.140182  7.7542295 6.5323944 6.9540815 8.537221  7.362826\n",
      "  7.060021  5.975339  6.2624345 6.496909  7.10893   6.4780993 7.245159\n",
      "  7.438424  8.291345  6.8069625 7.1789804 7.5475125 7.37929   6.57353\n",
      "  7.9080596 6.043729  7.396016  6.9468393 7.8197227 8.317829 ]\n",
      " [5.664112  7.3779354 6.124551  8.82495   6.404989  7.526384  7.4052277\n",
      "  6.7377267 7.55862   7.161505  6.5025167 7.7562823 8.602473  9.227909\n",
      "  7.6818976 7.5855865 8.116019  7.5097027 5.526461  8.473754  8.634022\n",
      "  7.360229  8.485624  7.7643566 5.759196  6.8027687 7.3477793 6.9798603\n",
      "  6.5770044 5.5585747 4.6793904 7.9488177 7.493966  8.382802  6.501154\n",
      "  8.268268  7.981219  7.5232425 7.597252  7.400927  6.778125  6.4173727\n",
      "  7.478718  6.5397625 6.819077  8.417635  7.025238  7.7744412]] \n",
      " shape = (4, 48) \n",
      " ndim = 2 \n",
      " dtype = float32 \n",
      " type = <class 'numpy.ndarray'> \n",
      "\n",
      "y_np2t =\n",
      " tensor([[5.5667, 8.0265, 6.5486, 8.1449, 7.3204, 7.5531, 7.8389, 5.9027, 8.4445,\n",
      "         7.1179, 7.3936, 7.7458, 7.1569, 9.1940, 8.8887, 7.7558, 7.4410, 8.7810,\n",
      "         6.4504, 7.1810, 8.4517, 7.4026, 7.9868, 7.2360, 7.0586, 6.9077, 8.6155,\n",
      "         7.2232, 6.8022, 5.6862, 6.2417, 7.9757, 7.4014, 8.2183, 6.4553, 8.3895,\n",
      "         8.2536, 7.2091, 8.2178, 7.7101, 6.5175, 6.6017, 8.4134, 5.6454, 7.9216,\n",
      "         7.5809, 6.9308, 7.9102],\n",
      "        [4.7944, 7.6596, 5.3806, 7.3439, 6.3041, 7.7558, 7.2205, 6.5450, 6.8329,\n",
      "         6.0705, 7.0618, 6.7989, 7.6537, 7.7555, 8.1527, 7.7323, 6.4669, 8.0622,\n",
      "         6.6007, 8.1995, 7.4816, 6.5633, 7.8278, 7.4247, 5.1542, 6.0255, 7.4717,\n",
      "         6.0527, 6.4665, 4.9215, 5.2722, 7.2250, 6.6226, 7.0848, 6.1495, 6.4953,\n",
      "         7.9893, 6.5039, 6.4224, 8.0600, 6.8567, 5.8803, 7.0927, 5.9097, 6.2198,\n",
      "         7.8803, 6.1650, 8.1800],\n",
      "        [5.2311, 7.6031, 6.3994, 8.3263, 6.7625, 7.9609, 7.8390, 5.6355, 8.1225,\n",
      "         6.4564, 7.5129, 8.0405, 7.5251, 8.5771, 8.8767, 8.3272, 7.2706, 8.4399,\n",
      "         7.0091, 7.3125, 8.1156, 6.8476, 8.1402, 7.7542, 6.5324, 6.9541, 8.5372,\n",
      "         7.3628, 7.0600, 5.9753, 6.2624, 6.4969, 7.1089, 6.4781, 7.2452, 7.4384,\n",
      "         8.2913, 6.8070, 7.1790, 7.5475, 7.3793, 6.5735, 7.9081, 6.0437, 7.3960,\n",
      "         6.9468, 7.8197, 8.3178],\n",
      "        [5.6641, 7.3779, 6.1246, 8.8250, 6.4050, 7.5264, 7.4052, 6.7377, 7.5586,\n",
      "         7.1615, 6.5025, 7.7563, 8.6025, 9.2279, 7.6819, 7.5856, 8.1160, 7.5097,\n",
      "         5.5265, 8.4738, 8.6340, 7.3602, 8.4856, 7.7644, 5.7592, 6.8028, 7.3478,\n",
      "         6.9799, 6.5770, 5.5586, 4.6794, 7.9488, 7.4940, 8.3828, 6.5012, 8.2683,\n",
      "         7.9812, 7.5232, 7.5973, 7.4009, 6.7781, 6.4174, 7.4787, 6.5398, 6.8191,\n",
      "         8.4176, 7.0252, 7.7744]]) \n",
      " shape = torch.Size([4, 48]) \n",
      " ndim = 2 \n",
      " dtype = torch.float32 \n",
      " type = <class 'torch.Tensor'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_np = y.numpy()\n",
    "print_info(y_np, 'y_np')\n",
    "\n",
    "y_np2t = torch.from_numpy(y_np)\n",
    "print_info(y_np2t, 'y_np2t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release the GPU resource\n",
    "\n",
    "Finally, click `File`->`Close and Halt` to close this notebook to prevent Python processes from occupying the GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLLecture",
   "language": "python",
   "name": "dllecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
