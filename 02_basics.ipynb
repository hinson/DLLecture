{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Constructing Deep Learning Models with TensorFlow/Pytorch\n",
    "\n",
    "##  Tensorflow and Pytorch\n",
    "\n",
    "* Many deep learning libraries have been developed util now: TensorFlow, Pytorch, Caffe, Mxnet, CNTK...\n",
    "* According to the resent reports, TensorFlow and Pytorch are the most popular libraries in deep learning research.\n",
    "* TensorFlow is suited to constructing static graph models, while Pytorch is good at dynamic(eager) modeling.\n",
    "* Though TensorFlow 2.0 will make earger mode be default, and Pytorch 1.0 will include caffe to handle static models,  at this time, we still employ them in the most suitable way separately.\n",
    "\n",
    "\n",
    "## Tensors\n",
    "\n",
    "Matrices are not enough in deep learning, since\n",
    "\n",
    "* one instance may be a 2d-array or over.\n",
    "    * a sentance: $ \\#\\left|\\{\\text{dims of word embedding}\\}\\right| \\times \\#\\left|\\{\\text{words of the sentance}\\}\\right| $\n",
    "    * a color image: $ \\#\\left|\\text{(R, G, B)}\\right| \\times \\#\\left|\\{\\text{horizontal pixels}\\}\\right| \\times \\#\\left|\\{\\text{vertical pixels}\\}\\right| $\n",
    "* mini-batch training is used commonly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set environment variables about use of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"       # eg. \"2, 3\" for multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Numpy\n",
    "\n",
    "#### Creation\n",
    "* `np.array` is the most common API to create an N dimensions(nd-) array. \n",
    "\n",
    "* About other creation APIs see [creation routines](https://docs.scipy.org/doc/numpy/reference/routines.array-creation.html) and [random sampling](https://docs.scipy.org/doc/numpy/reference/routines.random.html).\n",
    "\n",
    "* Operations on nd-arrays \"broadcast\" while the operands have different shapes. See [this](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(obj, name):\n",
    "    \n",
    "    print(\"{} =\\n\".format(name), obj, \"\\n shape =\", obj.shape, \n",
    "          \"\\n ndim =\", arr.ndim, \"\\n dtype =\", arr.dtype, \"\\n type =\", type(arr), \"\\n\")\n",
    "\n",
    "arr = np.array([0., 1., 2., 3.], dtype=np.float32)\n",
    "print_info(arr, \"arr\")\n",
    "\n",
    "vec = np.array(arr+1., ndmin=2).T    # .T means transpose\n",
    "print_info(vec, \"vec\")\n",
    "\n",
    "mat = np.vstack((arr**2, np.hstack((vec, vec-1., vec*2, vec/2))))\n",
    "print_info(mat, \"mat\")\n",
    "\n",
    "ten = np.stack((mat, mat))\n",
    "print_info(ten, \"ten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing, slicing and masking\n",
    "\n",
    "* Like lists in Python core, `[]` is used to index elements in nd-arrays. \n",
    "\n",
    "* The operators in `[]` can be array-like or slices, but using array-like returns a copy of data while using slices returns a view.\n",
    "\n",
    "* However, unlike the usage of multiple `[]` to index nd-lists, eg. `ls[d0][d1]`, `,` is used in `[]` for nd-arrays, eg. `arr[d0, d1]`.\n",
    "\n",
    "* Boolean operations can be performed masking thanks to broadcasting.\n",
    "\n",
    "For more detail, see [this](https://docs.scipy.org/doc/numpy/user/basics.indexing.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mat[3, 1], \"\\n\")\n",
    "\n",
    "print(mat[1:, -1:-3:-1], \"\\n\")     # same as [slice(1, None), slice(-1, -3, -1)]\n",
    "\n",
    "print(mat[np.arange(1, mat.shape[0]), np.array([3, 2, 1, 0])], \"\\n\")\n",
    "\n",
    "print(ten[..., 2], \"\\n\")           # same as [Ellipsis, 2]\n",
    "\n",
    "print(ten[ten>1], \"\\n\")\n",
    "\n",
    "print(arr[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With TensorFlow\n",
    "\n",
    "#### Creation\n",
    "Use the low level APIs to create a tensor object.\n",
    "\n",
    "* `tf.Variable`\n",
    "* `tf.constant`\n",
    "* `tf.placeholder`\n",
    "* `tf.SparseTensor`\n",
    "\n",
    "To know the usages of the APIs:\n",
    "1. push `shift` + `tab` while the cursor is behind the `(` of each name string to see the documentation of the API. \n",
    "2. Try to push `shift` + `tab` 2~4 times quickly.\n",
    "3. Push `esc` 1~2 times to close the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable()\n",
    "tf.random_uniform()\n",
    "tf.zeros()\n",
    "tf.placeholder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detail, see this [guide](https://www.tensorflow.org/guide/tensors).\n",
    "\n",
    "**Notice**: There is a _bug_ in the above official guide. When initializing a variable tensor with a certain dtype, do not use `tf.Variable({value}, tf.{dtype})` but `tf.Variable({value}, dtype=tf.{dtype})`. Because `dtype` is not the second argument of `tf.Variable` at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**. Create the following graph object in TensorFlow:\n",
    "* a _variable_ $ 60 \\times 128 $ random matrix $w$ with name `weight`\n",
    "* a _variable_ $128$-d zero vector $b$ with name `bias`\n",
    "* a $ 16 \\times 6 \\times 10 $ tensor _placeholder_ $x$ with name `input` \n",
    "\n",
    "All the `dtype`s must be `tf.float32`.\n",
    "\n",
    "Hints: \n",
    "1. There are many APIs to initialize variable tensor values, such as `tf.ones`, `tf.zeros`, `tf.fill` and `tf.random_*`. \n",
    "2. You can also use `numpy` to initialize variable or constant values.\n",
    "3. The names indicate the ones in TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):                     # using CPU\n",
    "    # your codes:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**. Construct a graph of $y = x'w + b$, where $x'$ is a $16 \\times 60$ matrix placeholder with name `input`.\n",
    "\n",
    "Hints:\n",
    "1. Use `x_` to indicate $x'$\n",
    "2. Use `tf.matmul` or `@` to perform the matrix multiplication.\n",
    "3. Tensors broadcast operations the same as arrays in numpy. \n",
    "4. The $y$ is a $16 \\times 128$ matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):                 # using a GPU\n",
    "    # your codes:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph execution\n",
    "\n",
    "Apply `tf.Session` to create a TensorFlow session to execute operations in a graph.\n",
    "\n",
    "A session should be closed when the execution finished. We can use `with` syntax in Python to handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    input = np.random.rand(16, 6, 10)\n",
    "    result = sess.run(y, feed_dict={x: input})\n",
    "    print_info(result, \"result\")\n",
    "    tf.summary.FileWriter('./runs', sess.graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Pytorch\n",
    "\n",
    "* Pytorch has a bundle of numpy-like APIs\n",
    "    * pythonic\n",
    "    * OOP- or functional style can be chosen in the programming.\n",
    "\n",
    "* `torch.tensor` is mainly used to create a tensor. \n",
    "* Also, there are many convenient APIs to construct some certain tensors, such as `torch.zeros`, `torch.ones` and `torch.rand*`.\n",
    "\n",
    "Now, review the process of looking up the documentations of APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor()\n",
    "torch.zeros()\n",
    "torch.rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**. Create the following tensor objects in Pytorch.\n",
    "* a $ 60 \\times 128 $ random matrix $w$\n",
    "* a $128$-d zero vector $b$\n",
    "* a $ 16 \\times 6 \\times 10 $ random tensor $x$ \n",
    "\n",
    "All the `dtype`s must be `torch.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**. Calculate $y = x'w + b$, where x' is a $16 \\times 60$ matrix.\n",
    "\n",
    "Hints:\n",
    "1. Use `torch.view` rather than `torch.reshape` to flatten.\n",
    "2. Use `torch.matmul` or `@` to perform the matrix multiplication.\n",
    "3. Broadcasting works as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your codes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y, 'y')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    z = y.to(device)\n",
    "    print(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors in Pytorch can be easily converted to numpy array, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = y.numpy()\n",
    "print_info(y_np, 'y')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "DLLecture",
   "language": "python",
   "name": "dllecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
